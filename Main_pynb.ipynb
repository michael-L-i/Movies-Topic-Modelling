{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/michael-L-i/Movies-Topic-Modelling/blob/main/Main_pynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8KX2jerZzdIq"
      },
      "outputs": [],
      "source": [
        "# packages for data scraping\n",
        "\n",
        "import pandas as pd\n",
        "import requests\n",
        "from urllib.parse import urljoin\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "!pip install selenium\n",
        "!apt-get update\n",
        "!apt install chromium-chromedriver\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium.webdriver.common.by import By\n",
        "\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "\n",
        "!apt install firefox\n",
        "!apt install xvfb\n",
        "!pip install pyvirtualdisplay\n",
        "from selenium.webdriver import FirefoxOptions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cmwN6Ks8AgBE"
      },
      "outputs": [],
      "source": [
        "# packages for topic modelling and sentiment analysis\n",
        "\n",
        "!pip install bertopic\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.tag import pos_tag\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "import string\n",
        "import os\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from bertopic.vectorizers import ClassTfidfTransformer\n",
        "from hdbscan import HDBSCAN\n",
        "from bertopic import BERTopic\n",
        "from umap import UMAP\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from bertopic.representation import KeyBERTInspired, MaximalMarginalRelevance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NgIXQqwY8OAs"
      },
      "outputs": [],
      "source": [
        "# packages for topic labelling and plotting\n",
        "!pip install openai\n",
        "from openai import OpenAI\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import plotly.express as px"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2qmcvKQpKbSa"
      },
      "outputs": [],
      "source": [
        "# options for Chrome driver necessary for Selenium to run on Colab\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument(\"--verbose\")\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--headless')\n",
        "options.add_argument('--disable-gpu')\n",
        "options.add_argument(\"--window-size=1920, 1200\")\n",
        "options.add_argument('--disable-dev-shm-usage')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhFTu4RqJ92S"
      },
      "source": [
        "# **Collection of Reviews Given Movie Name**\n",
        "\n",
        "**1. Overview**\n",
        "\n",
        "The site we chose to gather review data for movies from is [IMDb](https://www.imdb.com/). The get_movie_info() function takes in a querie, which represents the movie the user would want to get reviews from.\n",
        "\n",
        "**2. Process Structure**\n",
        "\n",
        "IMDb includes many reviews for each movie. The get_movie_info() function first takes a user querie for a movie name, like \"Mission: Impossible - Dead Reckoning Part One\" and finds the corresponding movie using IMDb's search feature.\n",
        "\n",
        "Then, once on the review page for the found movie, extract all the reviews. To extract more, we essentially click on the 'load more' button several times and compile all the available reviews.\n",
        "\n",
        "**3. Technicals**\n",
        "\n",
        "For the first step to find the movie URL, which on IMDb is specficied by a movie tag embedded within the URL, not the actual movie name. We do so using Selenium. Once the movie name is passed into the function, we create get the search URL for IMDb to find matching movies. Then, using Selenium we extract the URL stored for that movie.\n",
        "\n",
        "After getting the actual movie url, we run another driver for the reviews site. One barrier for getting reviews from IMDb is that many of the reviews are hidden, and they only appear when a 'load more' button is clicked. Selenium comes in handy in that it can simulate this process, allowing us to access many reviews on the page. Then, it is a simple process using BeautifulSoup to compile all the reviews.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PhRzEasAXmuJ"
      },
      "outputs": [],
      "source": [
        "def get_movie_info(querie, reviews):\n",
        "\n",
        "  querieURL = \"https://www.imdb.com/find?q=\" + querie\n",
        "\n",
        "  # finding URL of review page\n",
        "  opts = FirefoxOptions()\n",
        "  opts.add_argument(\"--headless\")\n",
        "\n",
        "  driverFirefox = webdriver.Firefox(options=opts)\n",
        "  driverFirefox.get(querieURL)\n",
        "  movie_url = \"\"\n",
        "  try:\n",
        "      movie = WebDriverWait(driverFirefox, 10).until(\n",
        "          EC.presence_of_element_located((By.CLASS_NAME, 'ipc-metadata-list-summary-item__t'))\n",
        "      )\n",
        "      movie_url = movie.get_attribute(\"href\")\n",
        "  finally:\n",
        "      driverFirefox.quit()\n",
        "\n",
        "  movie_url = \"reviews/?\".join(movie_url.split('?'))\n",
        "\n",
        "  # extracting reviews\n",
        "  driver = webdriver.Chrome(options=options)\n",
        "  driver.get(movie_url)\n",
        "\n",
        "  limit = 0 # limiting number of reviews (number of clicks to load more button) for the sake of runtime\n",
        "  while limit < 10:\n",
        "    try:\n",
        "        load_more_button = driver.find_element(By.CSS_SELECTOR, \".ipl-load-more__button\")\n",
        "        load_more_button.click()\n",
        "        time.sleep(float(np.random.randint(30,40)) / 10)\n",
        "    except:\n",
        "        break\n",
        "    limit += 1\n",
        "\n",
        "  html = driver.page_source\n",
        "  soup = BeautifulSoup(html, \"html.parser\")\n",
        "\n",
        "  # two different classes for texts based on IMDb's website structure\n",
        "  for review in soup.find_all(\"div\", class_=\"text show-more__control\"):\n",
        "    reviews.append(review.get_text()) # reviews array is pass by reference\n",
        "  for review in soup.find_all(\"div\", class_=\"text show-more__control clickable\"):\n",
        "    reviews.append(review.get_text())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzl1uLhHDuOK"
      },
      "source": [
        "# **Topic Modelling**\n",
        "\n",
        "**1. Overview**\n",
        "\n",
        "This step will look at the reviews and pull out major themes and topics for a particular movie. For example, for a Superhero movie, themes that may come out could be: *plot, action, sacrifice, visuals, music, etc.* We will assign these labels latter, but we want some sort of way to extract different aspects and themes of a movie.\n",
        "\n",
        "**2. Process Structure**\n",
        "\n",
        "To implement this process, we will be using the [BERTopic](https://maartengr.github.io/BERTopic/index.html) package. It was developed by Data Scientist Maarten Grootendorst in 2020. Essentially, utilizing transformers and c-TF-IDF, it is able to cluster texts in a corpus into clear categories. We will apply BERTopic to our segmentation of movie reviews into themes. This process is known in the NLP field as topic modelling.\n",
        "\n",
        "Before this, however, we need to clean the data to optimize performance of our eventual BERTopic model. We will split the entire corpus into smaller sentences (we will specify as length of 3 sentences). Essentially, we treat the corpus as containing many for 'documents' each one being at most 3 sentences. Further, we will remove most instances of actor names as they often take up the major representation of topics when we would rather look at other keywords.\n",
        "\n",
        "**3. Technicals**\n",
        "\n",
        "*BERTopic structure:*\n",
        "\n",
        "To do this unsupervised classification, we will be using the BERTopic model. Its pipeline involves several components. The first is embedding the texts into vectors in dense vector space, using an embedding model called [all-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2). The process follows with dimensionality reduction to make finding clusters easier, and then finding those well-formed clusters of these vectors. Next, we want extract key words that represent that topic from each cluster. We first employ a slightly altered version of TF-IDF that BERTopic provides. Then we chose to use MaximalMarginalRelevance to find keywords that best define that cluster. It does so by finding a balance between relevance to a unified topic within a cluster and diversity between topics in other clusters.\n",
        "\n",
        "Finally, we should get some well defined topics for our movie reviews!\n",
        "\n",
        "*Hyperparameter Tuning*\n",
        "\n",
        "Hyperparameter tuning is very important here as results are not optimal under certain parameters. The main components that were subject to tuning was with the UNAP model to identify the optimal dimension reduction to be able to form clear clusters but also have sufficient diversity from each other. Similarly, HSBSCAN was optimize to create clusters that could lead to the best topic modelling.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bIzFfSn1ARl5"
      },
      "outputs": [],
      "source": [
        "def remove_people_names(text):\n",
        "  tagged_words = pos_tag(nltk.word_tokenize(text))\n",
        "  filtered_words = [word for word, pos in tagged_words if pos != 'NNP'] # removes proper nouns\n",
        "  return ' '.join(filtered_words)\n",
        "\n",
        "# splits text into sentences of length <= 3\n",
        "def split_into_paragraphs(text_list, indexingDocs):\n",
        "    paragraphs = []\n",
        "    index = 0\n",
        "\n",
        "    for text in text_list:\n",
        "        sentences = sent_tokenize(text)\n",
        "        while len(sentences) > 0:\n",
        "            if len(sentences) < 3:\n",
        "                paragraphs.append(' '.join(sentences))\n",
        "                break\n",
        "            else:\n",
        "                paragraphs.append(' '.join(sentences[:3]))\n",
        "                indexingDocs[paragraphs[-1]] = index\n",
        "                sentences = sentences[3:]\n",
        "        index += 1\n",
        "    return paragraphs\n",
        "\n",
        "\"\"\"\n",
        "BERTopic Model\n",
        "\"\"\"\n",
        "def BERTopicModel(docs, reviewsDf):\n",
        "  # embedding, dimensionality reduction, and clustering\n",
        "  embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "  umap_model = UMAP(n_neighbors = 25, n_components=5, min_dist=0.0, metric='cosine', random_state=0)\n",
        "  hdbscan_model = HDBSCAN(min_cluster_size=len(docs)//75, metric='euclidean', cluster_selection_method='leaf', prediction_data=True)\n",
        "\n",
        "  # create topic representation from the clusters\n",
        "  vectorizer_model = CountVectorizer(stop_words=\"english\", min_df=2, max_df = len(reviewsDf), ngram_range=(1,2))\n",
        "  ctfidf_model = ClassTfidfTransformer(reduce_frequent_words=True)\n",
        "  representation_model = MaximalMarginalRelevance(diversity=0.3, top_n_words=10)\n",
        "\n",
        "  # define the pipeline\n",
        "  BERTopic_model = BERTopic(\n",
        "    embedding_model = embedding_model,\n",
        "    umap_model = umap_model,\n",
        "    hdbscan_model = hdbscan_model,\n",
        "    vectorizer_model = vectorizer_model,\n",
        "    ctfidf_model = ctfidf_model,\n",
        "    representation_model = representation_model,\n",
        "    calculate_probabilities = True,\n",
        "    top_n_words=10\n",
        "  )\n",
        "  return BERTopic_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBzLJMmg-8Al"
      },
      "source": [
        "# **Sentiment Analysis**\n",
        "\n",
        "**1. Overview**\n",
        "\n",
        "Now with clear set topics, we want to analyze the sentiment of the documents belonging to each category/topic. In the end, we should be able to graph the proportion of positive, neutral, and negative ratings for each topic.\n",
        "\n",
        "**2. Process Structure**\n",
        "\n",
        "The goal is to create a visualization of the proportion of positive, neutral, and negative reviews.\n",
        "\n",
        "One pertinent issue is that by splitting reviews into smaller sentence chunks, some of these chunks may only capture plot description which is common in movie reviews. In short, the plot may create an extremely negative sentiment score when that segment did not even include the review's opinion, which might be present in the rest of the review, but which we had cut up.\n",
        "\n",
        "To fix this, we will tie text segments, each back to their orignal review and evaluate the sentiment for the original review. We take this score and apply it as representing each text segment. In the cases where a review is overwhelmingly positive except for one section on a topic, this design will suffer. However, considering the large dataset size and general style of reviews (in terms the effect of bias), this design choice seems to provide good results.\n",
        "\n",
        "**3. Technicals**\n",
        "\n",
        "For the specific sentiment analysis, we will be using NLTK's SentimentIntensityAnalyzer which assigns a score of -1 to 1 (-1 being negative, 0 being neutral, and 1 being positive) sentiment in a text.\n",
        "\n",
        "Following the design strucutre described above, we will iterate through each sub-text and assign a sentiment score to each using the NLTK package. For each topic, we then count the number of positive, neutral, and negative reviews.\n",
        "\n",
        "We categorize sentiment by the score as follows:\n",
        "\n",
        "```\n",
        "positive: score >= 0.25\n",
        "negative: score <= -0.25\n",
        "neutral: -0.25 < score < 0.25\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6nnXg-rR2MYu"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "reviewsDict: Dictionary with keys (0 - #topics) with list of\n",
        "all ORIGINAL reviews that have sub-texts belonging to that topic\n",
        "\"\"\"\n",
        "def documentReversal(topicsDf, reviewsDf, docs, indexingDocs, probs):\n",
        "  reviewsDict = defaultdict(list)\n",
        "\n",
        "  for i in range(len(probs)):\n",
        "    docIndex = np.argmax(probs[i])\n",
        "    reviewsDict[docIndex].append(reviewsDf[\"Reviews\"][indexingDocs[docs[i]]])\n",
        "\n",
        "  return reviewsDict\n",
        "\n",
        "\"\"\"\n",
        "Sentiment Analysis\n",
        "\"\"\"\n",
        "def sentimentSegmentation(neg, neu, pos, reviewsDict):\n",
        "  sentiment_for_each_topic = []\n",
        "  sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "  for i in range(0, len(reviewsDict) - 1):\n",
        "    total_score_for_topic = 0\n",
        "    total_count_for_topic = 0\n",
        "\n",
        "    for text in reviewsDict[i]:\n",
        "      sentiment_score = sia.polarity_scores(text)['compound']\n",
        "      if (sentiment_score <= -0.25):\n",
        "        neg[i] += 1\n",
        "      elif (sentiment_score >= 0.25):\n",
        "        pos[i] += 1\n",
        "      else:\n",
        "        neu[i] += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBURbq859ftD"
      },
      "source": [
        "# **Topic Labelling**\n",
        "\n",
        "**1. Overview**\n",
        "\n",
        "With defined clusters and keyword representation of those clusters, we will begin to assign topic labels to those clusters. The goal is to create a plot of the sentiment towards each cluster paired with a topic label for that cluster.\n",
        "\n",
        "**2. Process Strucutre**\n",
        "\n",
        "The first step is to generate the labels for each category, which we do using OpenAI's GPT-3.5 API. This, however, generates often overlapping categories, and some cleaning is required. This is done through another embedding and comparison process to essentially group closely related topic labels into one. Then we should be able to plot the sentiment with a corresponding topic label, concluding the main goal of this project!\n",
        "\n",
        "**3. Technicals**\n",
        "\n",
        "For the first step to generate topic labels using GPT-3.5, passing through key words and representative documents for each topic, paired with some prompt engineering.\n",
        "\n",
        "Next, we want to iron out the topics so that there is sufficient diversity between those labels by grouping related categories. We do so by first embedding an array of the keywords for each topic alongside the assigned topic label. Next, we calculate the similarities between each embedding, considering groups with high enough similarity for grouping being a cosine similarity of 0.5. The grouping is done in the relabelling() function.\n",
        "\n",
        "In the end, we should end up with fairly distinct topics that would represent major themes or components of a movie."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L44yeU6gANQP"
      },
      "outputs": [],
      "source": [
        "def generate_labels(topicsDf):\n",
        "  client = OpenAI(api_key='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')\n",
        "\n",
        "  INSTRUCTIONS = \"\"\"You are a topic labeler for a movie review segmentation model. The developers have already clustered movie reviews into categories, and each category was assigned a list of the most common words (called 'Representation') that represent it. You will be given this list of representative words along with a few example reviews (called 'Representative_Docs') from that category.\n",
        "\n",
        "Your task is to output a single, concise category label that best describes the given representative words and example reviews, regardless of the sentiment expressed in the reviews. The label should be a short phrase or a few words, such as 'Music', 'Acting', 'Story Arc', 'Math/Professor Elements', 'Character Depth', 'Emotional Engagement', or 'Messaging/Morals'.\n",
        "\n",
        "The input will be provided in the following format:\n",
        "\n",
        "Here are the representative words for this cluster:\n",
        "[list of representative words separated by commas or newlines]\n",
        "\n",
        "Here are some representative reviews:\n",
        "[multiple example reviews separated by newlines]\n",
        "\n",
        "Give a label for this segmented category.\n",
        "\n",
        "Please respond with only the category label, without any additional explanation or context. If you cannot determine a suitable label from the given information, respond with 'Unclear'. When determining the category label, focus on the topics or aspects of the movie being discussed, rather than the overall sentiment or opinion expressed in the reviews.\"\"\"\n",
        "\n",
        "  responses = []\n",
        "  messages = [\n",
        "      {\"role\": \"system\", \"content\": INSTRUCTIONS}\n",
        "      ]\n",
        "\n",
        "  for index, row in topicsDf.iterrows():\n",
        "    messages.append(\n",
        "        {\"role\": \"user\", \"content\": f\"Here are the representative words for this cluster:\\n\\n{topicsDf['Representation'].iloc[index]}\\n\\nHere are some representative reviews:{topicsDf['Representative_Docs'].iloc[index][:3]}. Give a label for this segmented category.\"},\n",
        "    )\n",
        "    response = client.chat.completions.create(\n",
        "      model=\"gpt-3.5-turbo\",\n",
        "      messages=messages\n",
        "    )\n",
        "    responses.append(response.choices[0].message.content)\n",
        "    messages.append(\n",
        "        {\"role\": \"assistant\", \"content\": response.choices[0].message.content},\n",
        "    )\n",
        "\n",
        "  return responses\n",
        "\n",
        "\n",
        "def preprocess_embeddings(labels, topicsDf):\n",
        "  keywordsList = []\n",
        "\n",
        "  for index, row in topicsDf.iterrows():\n",
        "    key_words = topicsDf['Representation'].iloc[index][:10]\n",
        "    keywordsList.append([labels[index - 1]] + key_words)\n",
        "\n",
        "  return keywordsList\n",
        "\n",
        "\n",
        "def embed(labels, topicsDf):\n",
        "  client = OpenAI(api_key='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')\n",
        "\n",
        "  embeddings = []\n",
        "\n",
        "  for keywords in preprocess_embeddings(labels, topicsDf):\n",
        "    response = client.embeddings.create(\n",
        "      input=keywords,\n",
        "      model=\"text-embedding-3-small\"\n",
        "  )\n",
        "\n",
        "    embeddings.append(response.data[0].embedding)\n",
        "  return embeddings\n",
        "\n",
        "\n",
        "def calcSimilarities(embeddings):\n",
        "  similarity_threshold = 0.5\n",
        "\n",
        "  embeddings = np.array(embeddings)\n",
        "  similarities = cosine_similarity(embeddings)\n",
        "  similaritiesArr = []\n",
        "\n",
        "  for i in range(len(similarities)):\n",
        "      for j in range(i + 1, len(similarities)):\n",
        "          similarity = similarities[i, j]\n",
        "          if similarity > similarity_threshold:\n",
        "            similaritiesArr.append([i, j, similarity])\n",
        "\n",
        "  similaritiesArr = np.array(similaritiesArr)\n",
        "  similaritiesArrSorted = []\n",
        "\n",
        "  if (len(similaritiesArr) > 0):\n",
        "    similaritiesArrSorted = similaritiesArr[similaritiesArr[:, 2].argsort()[::-1]]\n",
        "  else:\n",
        "    similaritiesArrSorted = similaritiesArrSorted\n",
        "\n",
        "  return similaritiesArrSorted\n",
        "\n",
        "\n",
        "def relabelling(similaritiesArrSorted, neg, neu, pos, labels):\n",
        "  for ele in similaritiesArrSorted:\n",
        "    if (len(labels) <= 5):\n",
        "      break\n",
        "\n",
        "    neg[int(ele[0])] += neg[int(ele[1])]\n",
        "    neu[int(ele[0])] += neu[int(ele[1])]\n",
        "    pos[int(ele[0])] += pos[int(ele[1])]\n",
        "\n",
        "    neg[int(ele[1])] = 0\n",
        "    neu[int(ele[1])] = 0\n",
        "    pos[int(ele[1])] = 0\n",
        "\n",
        "  index = 0\n",
        "  while (index < len(neg)):\n",
        "    if neg[index] == 0 and neu[index] == 0 and pos[index] == 0:\n",
        "      del neg[index]\n",
        "      del neu[index]\n",
        "      del pos[index]\n",
        "      del labels[index]\n",
        "      index -= 1\n",
        "    index += 1\n",
        "\n",
        "  for i in range(len(neg)):\n",
        "    tot = neg[i]+neu[i]+pos[i]\n",
        "    neg[i] = neg[i]/tot\n",
        "    neu[i] = neu[i]/tot\n",
        "    pos[i] = pos[i]/tot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHtmxnTaHqWw"
      },
      "source": [
        "# **Running Everything**\n",
        "\n",
        "Finally, we create the run() function that will compile all our functions and create a plot of the sentiment for each topic/theme in a movie."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6rvQiaE_HqC6"
      },
      "outputs": [],
      "source": [
        "def run():\n",
        "  reviews = []\n",
        "  querie = input(\"Input a movie to gather reviews! \")\n",
        "  get_movie_info(querie, reviews)\n",
        "\n",
        "  reviewsDf = pd.DataFrame({\"Reviews\": reviews})\n",
        "  reviewsDf['Reviews'] = reviewsDf['Reviews'].apply(lambda x: remove_people_names(x))\n",
        "\n",
        "  indexingDocs = defaultdict(int)\n",
        "  # docs is the new corpus to be inputted into BERTopic model\n",
        "  docs = split_into_paragraphs(reviewsDf['Reviews'], indexingDocs)\n",
        "\n",
        "  \"\"\"\n",
        "  topics stores which topic each 'document' in the corpus belongs to\n",
        "  probs stores the probability of each 'document' belonging to all categories\n",
        "  -1 label for a topic are attributed to 'documents' that don't fit well with topics\n",
        "  \"\"\"\n",
        "  BERTopic_model = BERTopicModel(docs, reviewsDf)\n",
        "  topics, probs = BERTopic_model.fit_transform(docs)\n",
        "\n",
        "  topicsDf = BERTopic_model.get_topic_info() # DataFrame with information about each topic\n",
        "  topicsDf = topicsDf.loc[1:].reset_index(drop=True)\n",
        "\n",
        "  # clearning topicsDf for categories with < 10 representative keywords\n",
        "  for i in range(len(topicsDf)):\n",
        "    if topicsDf[\"Representation\"][i][-1] == '':\n",
        "      topicsDf = topicsDf.drop(i)\n",
        "      probs = np.delete(probs, i, axis = 1)\n",
        "  topicsDf = topicsDf.reset_index(drop=True)\n",
        "\n",
        "  # sentiment evaluation for each topic\n",
        "  reviewsDict = documentReversal(topicsDf, reviewsDf, docs, indexingDocs, probs)\n",
        "  neg = [0]*(len(reviewsDict))\n",
        "  neu = [0]*(len(reviewsDict))\n",
        "  pos = [0]*(len(reviewsDict))\n",
        "  sentimentSegmentation(neg, neu, pos, reviewsDict)\n",
        "\n",
        "  # initial topic labels\n",
        "  labels = generate_labels(topicsDf)\n",
        "\n",
        "  # fine tuning topic labels\n",
        "  embeddings = embed(labels, topicsDf)\n",
        "  similaritiesArrSorted = calcSimilarities(embeddings)\n",
        "  relabelling(similaritiesArrSorted, neg, neu, pos, labels)\n",
        "\n",
        "  finalDf = pd.DataFrame({\"Topics\": labels, \"Negative\": neg, \"Neutral\": neu, \"Positive\": pos})\n",
        "\n",
        "  # deleting rows with \"Unclear\" label\n",
        "  for i in range(len(finalDf)):\n",
        "    if (finalDf.loc[i][\"Topics\"] == \"Unclear\"):\n",
        "      del neg[i]\n",
        "      del neu[i]\n",
        "      del pos[i]\n",
        "  finalDf = finalDf[finalDf[\"Topics\"] != \"Unclear\"].reset_index(drop=True)\n",
        "\n",
        "  # plotting\n",
        "  fig = px.bar(finalDf, y=\"Topics\", x=[\"Negative\", \"Neutral\", \"Positive\"],\n",
        "              title=\"Sentiment Distribution by Topic\",\n",
        "              labels={\"value\": \"Sentiment Distribution\", \"Topics\": \"Topics\"},\n",
        "              color_discrete_map={\"Negative\": \"red\", \"Neutral\": \"gray\", \"Positive\": \"green\"},\n",
        "               orientation = \"h\"\n",
        "               )\n",
        "  fig.update_layout(\n",
        "    font=dict(\n",
        "        size=13\n",
        "    )\n",
        "  )\n",
        "  fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "D74DG7VvhxmK",
        "outputId": "fa11a6dc-f59b-4171-abbf-0034ced8eb81"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"88c94e33-2768-4593-b945-605d94fce92d\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"88c94e33-2768-4593-b945-605d94fce92d\")) {                    Plotly.newPlot(                        \"88c94e33-2768-4593-b945-605d94fce92d\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"variable=Negative\\u003cbr\\u003eSentiment Distribution=%{x}\\u003cbr\\u003eTopics=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"Negative\",\"marker\":{\"color\":\"red\",\"pattern\":{\"shape\":\"\"}},\"name\":\"Negative\",\"offsetgroup\":\"Negative\",\"orientation\":\"h\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[0.13141025641025642,0.12340425531914893,0.0797872340425532,0.11042944785276074,0.11299435028248588,0.18947368421052632,0.08187134502923976,0.14285714285714285],\"xaxis\":\"x\",\"y\":[\"Dream Logic\",\"Film Criticism\",\"Positive Reception\",\"Acting Quality\",\"Psychological Depth\",\"Plot Critique\",\"Nolan's Cinematic Universe\",\"Critical Rating Evaluation\"],\"yaxis\":\"y\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"variable=Neutral\\u003cbr\\u003eSentiment Distribution=%{x}\\u003cbr\\u003eTopics=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"Neutral\",\"marker\":{\"color\":\"gray\",\"pattern\":{\"shape\":\"\"}},\"name\":\"Neutral\",\"offsetgroup\":\"Neutral\",\"orientation\":\"h\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[0.041666666666666664,0.00851063829787234,0.005319148936170213,0.0,0.05084745762711865,0.03859649122807018,0.029239766081871343,0.0],\"xaxis\":\"x\",\"y\":[\"Dream Logic\",\"Film Criticism\",\"Positive Reception\",\"Acting Quality\",\"Psychological Depth\",\"Plot Critique\",\"Nolan's Cinematic Universe\",\"Critical Rating Evaluation\"],\"yaxis\":\"y\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"variable=Positive\\u003cbr\\u003eSentiment Distribution=%{x}\\u003cbr\\u003eTopics=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"Positive\",\"marker\":{\"color\":\"green\",\"pattern\":{\"shape\":\"\"}},\"name\":\"Positive\",\"offsetgroup\":\"Positive\",\"orientation\":\"h\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[0.8269230769230769,0.8680851063829788,0.9148936170212766,0.8895705521472392,0.8361581920903954,0.7719298245614035,0.8888888888888888,0.8571428571428571],\"xaxis\":\"x\",\"y\":[\"Dream Logic\",\"Film Criticism\",\"Positive Reception\",\"Acting Quality\",\"Psychological Depth\",\"Plot Critique\",\"Nolan's Cinematic Universe\",\"Critical Rating Evaluation\"],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Sentiment Distribution\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Topics\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Sentiment Distribution by Topic\"},\"barmode\":\"relative\",\"font\":{\"size\":13}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('88c94e33-2768-4593-b945-605d94fce92d');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "run()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}